{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a6b66d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-22T10:58:51.669638Z",
     "start_time": "2022-05-22T10:58:50.940727Z"
    }
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61e540b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-22T10:59:07.390433Z",
     "start_time": "2022-05-22T10:59:07.382112Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 5000\n",
    "alpha = 0.1\n",
    "HADOOP_PATH = '/LogReg'\n",
    "INPUT_PATH = '/home/islamahmed1092/Desktop/hotel-booking-demand-analysis/train.csv'\n",
    "MAPPER_PATH = '/home/islamahmed1092/Desktop/hotel-booking-demand-analysis/LogReg/mapper.py'\n",
    "REDUCER_PATH = '/home/islamahmed1092/Desktop/hotel-booking-demand-analysis/LogReg/reducer.py'\n",
    "STREAMING_JAR = '/usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.3.0.jar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cd31860",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-22T10:59:23.547272Z",
     "start_time": "2022-05-22T10:59:13.582484Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-22 12:59:14,658 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted /LogReg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-22 12:59:16,938 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2022-05-22 12:59:19,420 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2022-05-22 12:59:21,865 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['hdfs', 'dfs', '-put', '/home/islamahmed1092/Desktop/hotel-booking-demand-analysis/train.csv', '/LogReg/Input'], returncode=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run([\"hdfs\", \"dfs\", \"-rm\", \"-r\", HADOOP_PATH])\n",
    "subprocess.run([\"hdfs\", \"dfs\", \"-mkdir\", HADOOP_PATH])\n",
    "subprocess.run([\"hdfs\", \"dfs\", \"-mkdir\", f'{HADOOP_PATH}/Input'])\n",
    "subprocess.run([\"hdfs\", \"dfs\", \"-put\", INPUT_PATH, f'{HADOOP_PATH}/Input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fa5a3f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-22T11:00:43.762872Z",
     "start_time": "2022-05-22T10:59:34.905380Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-22 12:59:35,857 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "rm: `/LogReg/Output': No such file or directory\n",
      "2022-05-22 12:59:38,201 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.\n",
      "2022-05-22 12:59:38,361 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "packageJobJar: [/home/islamahmed1092/Desktop/hotel-booking-demand-analysis/LogReg/mapper.py, /home/islamahmed1092/Desktop/hotel-booking-demand-analysis/LogReg/reducer.py, /tmp/hadoop-unjar5797635777785629155/] [] /tmp/streamjob3630650768291469507.jar tmpDir=null\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-22 12:59:39,580 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2022-05-22 12:59:39,892 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2022-05-22 12:59:40,159 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/islamahmed1092/.staging/job_1653215883034_0002\n",
      "2022-05-22 12:59:40,738 INFO mapred.FileInputFormat: Total input files to process : 1\n",
      "2022-05-22 12:59:40,799 INFO mapreduce.JobSubmitter: number of splits:2\n",
      "2022-05-22 12:59:41,108 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1653215883034_0002\n",
      "2022-05-22 12:59:41,108 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
      "2022-05-22 12:59:41,342 INFO conf.Configuration: resource-types.xml not found\n",
      "2022-05-22 12:59:41,342 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.\n",
      "2022-05-22 12:59:41,439 INFO impl.YarnClientImpl: Submitted application application_1653215883034_0002\n",
      "2022-05-22 12:59:41,510 INFO mapreduce.Job: The url to track the job: http://islamahmed1092:8088/proxy/application_1653215883034_0002/\n",
      "2022-05-22 12:59:41,514 INFO mapreduce.Job: Running job: job_1653215883034_0002\n",
      "2022-05-22 12:59:49,688 INFO mapreduce.Job: Job job_1653215883034_0002 running in uber mode : false\n",
      "2022-05-22 12:59:49,690 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "2022-05-22 13:00:08,994 INFO mapreduce.Job:  map 67% reduce 0%\n",
      "2022-05-22 13:00:36,464 INFO mapreduce.Job:  map 83% reduce 0%\n",
      "2022-05-22 13:00:37,473 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "2022-05-22 13:00:42,510 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "2022-05-22 13:00:43,536 INFO mapreduce.Job: Job job_1653215883034_0002 completed successfully\n",
      "2022-05-22 13:00:43,668 INFO mapreduce.Job: Counters: 54\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=1483\n",
      "\t\tFILE: Number of bytes written=807502\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=47020276\n",
      "\t\tHDFS: Number of bytes written=715\n",
      "\t\tHDFS: Number of read operations=11\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tData-local map tasks=2\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=88856\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=3481\n",
      "\t\tTotal time spent by all map tasks (ms)=88856\n",
      "\t\tTotal time spent by all reduce tasks (ms)=3481\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=88856\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=3481\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=90988544\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=3564544\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=81298\n",
      "\t\tMap output records=60\n",
      "\t\tMap output bytes=1357\n",
      "\t\tMap output materialized bytes=1489\n",
      "\t\tInput split bytes=192\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=30\n",
      "\t\tReduce shuffle bytes=1489\n",
      "\t\tReduce input records=60\n",
      "\t\tReduce output records=30\n",
      "\t\tSpilled Records=120\n",
      "\t\tShuffled Maps =2\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tGC time elapsed (ms)=146\n",
      "\t\tCPU time spent (ms)=73030\n",
      "\t\tPhysical memory (bytes) snapshot=766074880\n",
      "\t\tVirtual memory (bytes) snapshot=8242450432\n",
      "\t\tTotal committed heap usage (bytes)=635437056\n",
      "\t\tPeak Map Physical memory (bytes)=337371136\n",
      "\t\tPeak Map Virtual memory (bytes)=3264851968\n",
      "\t\tPeak Reduce Physical memory (bytes)=214921216\n",
      "\t\tPeak Reduce Virtual memory (bytes)=2754723840\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=47020084\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=715\n",
      "2022-05-22 13:00:43,669 INFO streaming.StreamJob: Output directory: /LogReg/Output\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['hadoop', 'jar', '/usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.3.0.jar', '-file', '/home/islamahmed1092/Desktop/hotel-booking-demand-analysis/LogReg/mapper.py', '-file', '/home/islamahmed1092/Desktop/hotel-booking-demand-analysis/LogReg/reducer.py', '-input', '/LogReg/Input', '-output', '/LogReg/Output', '-mapper', '/home/islamahmed1092/Desktop/hotel-booking-demand-analysis/LogReg/mapper.py 5000 0.1', '-reducer', '/home/islamahmed1092/Desktop/hotel-booking-demand-analysis/LogReg/reducer.py'], returncode=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run([\"hdfs\", \"dfs\", \"-rm\", \"-r\", f'{HADOOP_PATH}/Output'])\n",
    "\n",
    "subprocess.run(\n",
    "    [\n",
    "        \"hadoop\",\n",
    "        \"jar\", \n",
    "        STREAMING_JAR,\n",
    "        \"-file\",\n",
    "        MAPPER_PATH,\n",
    "        \"-file\",\n",
    "        REDUCER_PATH,\n",
    "        \"-input\",\n",
    "        f'{HADOOP_PATH}/Input',\n",
    "        \"-output\",\n",
    "        f'{HADOOP_PATH}/Output',\n",
    "        \"-mapper\",\n",
    "        f'{MAPPER_PATH} {epochs} {alpha}',\n",
    "        \"-reducer\",\n",
    "        f'{REDUCER_PATH}'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dda6ff5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-22T11:00:51.165156Z",
     "start_time": "2022-05-22T11:00:48.749256Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-22 13:00:49,699 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,-0.7144573037575762\t\n",
      "1,0.12912702550131577\t\n",
      "10,0.09820548608328562\t\n",
      "11,-0.001327100918906068\t\n",
      "12,0.10297683497559008\t\n",
      "13,0.847159993965653\t\n",
      "14,0.23111291501349718\t\n",
      "15,0.23526637275705548\t\n",
      "16,-0.12299507050024866\t\n",
      "17,1.6531728440025901\t\n",
      "18,-0.5573639063375297\t\n",
      "19,-0.4555771010476153\t\n",
      "2,0.44043283048774834\t\n",
      "20,0.5741756860539273\t\n",
      "21,-0.21538499434841513\t\n",
      "22,1.2511612970072081\t\n",
      "23,0.055799086493396086\t\n",
      "24,-0.05537501781638641\t\n",
      "25,-0.061042177697221284\t\n",
      "26,0.564246015037948\t\n",
      "27,0.27804123052794083\t\n",
      "28,-1.5984819071400043\t\n",
      "29,-0.4693249829775594\t\n",
      "3,0.24674655627851183\t\n",
      "4,-0.04545293006039591\t\n",
      "5,0.06538121725783279\t\n",
      "6,-0.004772131446007549\t\n",
      "7,0.037373684074283965\t\n",
      "8,0.06946020189358049\t\n",
      "9,0.12708481855004816\t\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['hdfs', 'dfs', '-cat', '/LogReg/Output/*'], returncode=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run([\"hdfs\", \"dfs\", \"-cat\", f'{HADOOP_PATH}/Output/*'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "caa5ca6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-22T11:01:10.107022Z",
     "start_time": "2022-05-22T11:01:07.456540Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-22 13:01:08,572 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part-00000\n",
      "_SUCCESS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['ls', 'Output'], returncode=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run([\"rm\", \"-r\", f'{os.getcwd()}/Output'])\n",
    "subprocess.run([\"hdfs\", \"dfs\", \"-get\", f'{HADOOP_PATH}/Output/', os.getcwd()])\n",
    "\n",
    "subprocess.run([\"ls\", 'Output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d46a8f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-22T11:01:16.754045Z",
     "start_time": "2022-05-22T11:01:16.722726Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>w</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.714457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.129127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.440433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.246747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.045453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index         w\n",
       "0      0 -0.714457\n",
       "1      1  0.129127\n",
       "2      2  0.440433\n",
       "3      3  0.246747\n",
       "4      4 -0.045453"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = pd.read_csv('Output/part-00000', header=None, names=[\"index\", \"w\"])\n",
    "out = out.sort_values('index').reset_index(drop=True)\n",
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94566257",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-22T11:01:30.270180Z",
     "start_time": "2022-05-22T11:01:30.260460Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 1)\n"
     ]
    }
   ],
   "source": [
    "w = out['w'].to_numpy().reshape(-1, 1)\n",
    "print(w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a10aef39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-22T11:01:39.807219Z",
     "start_time": "2022-05-22T11:01:39.408080Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34842, 29)\n",
      "(34842, 1)\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv('../test.csv', header=None)\n",
    "X_test = test_data.iloc[: , :-1].to_numpy()\n",
    "y_test = test_data.iloc[: , -1].to_numpy().reshape(-1,1)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f975114d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-22T11:01:44.477263Z",
     "start_time": "2022-05-22T11:01:44.463602Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34842, 30)\n"
     ]
    }
   ],
   "source": [
    "X_test_aug = np.pad(X_test, [(0,0), (1,0)], mode='constant', constant_values=1)\n",
    "print(X_test_aug.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2e29a2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-22T11:38:34.735541Z",
     "start_time": "2022-05-22T11:38:34.628844Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Logistic Regression is : 0.8030537856609838\n",
      "Confusion Matrix : \n",
      "[[20072  1905]\n",
      " [ 4957  7908]]\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.91      0.85     21977\n",
      "           1       0.81      0.61      0.70     12865\n",
      "\n",
      "    accuracy                           0.80     34842\n",
      "   macro avg       0.80      0.76      0.78     34842\n",
      "weighted avg       0.80      0.80      0.80     34842\n",
      "\n"
     ]
    }
   ],
   "source": [
    "probs = 1/(1+np.exp(-(X_test_aug @ w)))\n",
    "predictions = np.where(probs > 0.5, 1, 0)\n",
    "acc_lr = accuracy_score(y_test, predictions)\n",
    "conf = confusion_matrix(y_test, predictions)\n",
    "clf_report = classification_report(y_test, predictions)\n",
    "\n",
    "print(f\"Accuracy Score of Logistic Regression is : {acc_lr}\")\n",
    "print(f\"Confusion Matrix : \\n{conf}\")\n",
    "print(f\"Classification Report : \\n{clf_report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961452de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
