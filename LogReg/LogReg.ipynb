{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a6b66d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-20T19:26:55.612429Z",
     "start_time": "2022-05-20T19:26:54.932638Z"
    }
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61e540b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-20T19:26:55.621730Z",
     "start_time": "2022-05-20T19:26:55.615015Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 10000\n",
    "alpha = 0.1\n",
    "HADOOP_PATH = '/LogReg'\n",
    "INPUT_PATH = '/home/islamahmed1092/Desktop/hotel-booking-demand-analysis/train.csv'\n",
    "MAPPER_PATH = '/home/islamahmed1092/Desktop/hotel-booking-demand-analysis/LogReg/mapper.py'\n",
    "REDUCER_PATH = '/home/islamahmed1092/Desktop/hotel-booking-demand-analysis/LogReg/reducer.py'\n",
    "STREAMING_JAR = '/usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.3.0.jar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cd31860",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-20T19:27:03.259940Z",
     "start_time": "2022-05-20T19:26:55.623467Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-20 21:26:56,422 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted /LogReg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-20 21:26:58,367 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2022-05-20 21:27:00,248 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2022-05-20 21:27:02,033 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['hdfs', 'dfs', '-put', '/home/islamahmed1092/Desktop/hotel-booking-demand-analysis/train.csv', '/LogReg/Input'], returncode=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run([\"hdfs\", \"dfs\", \"-rm\", \"-r\", HADOOP_PATH])\n",
    "subprocess.run([\"hdfs\", \"dfs\", \"-mkdir\", HADOOP_PATH])\n",
    "subprocess.run([\"hdfs\", \"dfs\", \"-mkdir\", f'{HADOOP_PATH}/Input'])\n",
    "subprocess.run([\"hdfs\", \"dfs\", \"-put\", INPUT_PATH, f'{HADOOP_PATH}/Input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fa5a3f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-20T19:31:47.550347Z",
     "start_time": "2022-05-20T19:31:04.713995Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-20 21:31:05,374 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "rm: `/LogReg/Output': No such file or directory\n",
      "2022-05-20 21:31:06,983 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.\n",
      "2022-05-20 21:31:07,087 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "packageJobJar: [/home/islamahmed1092/Desktop/hotel-booking-demand-analysis/LogReg/mapper.py, /home/islamahmed1092/Desktop/hotel-booking-demand-analysis/LogReg/reducer.py, /tmp/hadoop-unjar11795760747935486770/] [] /tmp/streamjob12690188619892220475.jar tmpDir=null\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-20 21:31:07,791 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2022-05-20 21:31:07,948 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2022-05-20 21:31:08,182 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/islamahmed1092/.staging/job_1653075029867_0001\n",
      "2022-05-20 21:31:09,022 INFO mapred.FileInputFormat: Total input files to process : 1\n",
      "2022-05-20 21:31:09,077 INFO mapreduce.JobSubmitter: number of splits:2\n",
      "2022-05-20 21:31:09,336 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1653075029867_0001\n",
      "2022-05-20 21:31:09,337 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
      "2022-05-20 21:31:09,538 INFO conf.Configuration: resource-types.xml not found\n",
      "2022-05-20 21:31:09,539 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.\n",
      "2022-05-20 21:31:09,783 INFO impl.YarnClientImpl: Submitted application application_1653075029867_0001\n",
      "2022-05-20 21:31:09,830 INFO mapreduce.Job: The url to track the job: http://islamahmed1092:8088/proxy/application_1653075029867_0001/\n",
      "2022-05-20 21:31:09,832 INFO mapreduce.Job: Running job: job_1653075029867_0001\n",
      "2022-05-20 21:31:17,006 INFO mapreduce.Job: Job job_1653075029867_0001 running in uber mode : false\n",
      "2022-05-20 21:31:17,008 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "2022-05-20 21:31:34,210 INFO mapreduce.Job:  map 67% reduce 0%\n",
      "2022-05-20 21:31:41,294 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "2022-05-20 21:31:46,332 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "2022-05-20 21:31:47,358 INFO mapreduce.Job: Job job_1653075029867_0001 completed successfully\n",
      "2022-05-20 21:31:47,501 INFO mapreduce.Job: Counters: 54\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=1483\n",
      "\t\tFILE: Number of bytes written=807505\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=47020276\n",
      "\t\tHDFS: Number of bytes written=715\n",
      "\t\tHDFS: Number of read operations=11\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tData-local map tasks=2\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=44664\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=2590\n",
      "\t\tTotal time spent by all map tasks (ms)=44664\n",
      "\t\tTotal time spent by all reduce tasks (ms)=2590\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=44664\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=2590\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=45735936\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=2652160\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=81298\n",
      "\t\tMap output records=60\n",
      "\t\tMap output bytes=1357\n",
      "\t\tMap output materialized bytes=1489\n",
      "\t\tInput split bytes=192\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=30\n",
      "\t\tReduce shuffle bytes=1489\n",
      "\t\tReduce input records=60\n",
      "\t\tReduce output records=30\n",
      "\t\tSpilled Records=120\n",
      "\t\tShuffled Maps =2\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tGC time elapsed (ms)=112\n",
      "\t\tCPU time spent (ms)=87060\n",
      "\t\tPhysical memory (bytes) snapshot=786993152\n",
      "\t\tVirtual memory (bytes) snapshot=8250503168\n",
      "\t\tTotal committed heap usage (bytes)=662700032\n",
      "\t\tPeak Map Physical memory (bytes)=343506944\n",
      "\t\tPeak Map Virtual memory (bytes)=3265536000\n",
      "\t\tPeak Reduce Physical memory (bytes)=220549120\n",
      "\t\tPeak Reduce Virtual memory (bytes)=2755719168\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=47020084\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=715\n",
      "2022-05-20 21:31:47,501 INFO streaming.StreamJob: Output directory: /LogReg/Output\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['hadoop', 'jar', '/usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.3.0.jar', '-file', '/home/islamahmed1092/Desktop/hotel-booking-demand-analysis/LogReg/mapper.py', '-file', '/home/islamahmed1092/Desktop/hotel-booking-demand-analysis/LogReg/reducer.py', '-input', '/LogReg/Input', '-output', '/LogReg/Output', '-mapper', '/home/islamahmed1092/Desktop/hotel-booking-demand-analysis/LogReg/mapper.py 5000 0.1', '-reducer', '/home/islamahmed1092/Desktop/hotel-booking-demand-analysis/LogReg/reducer.py'], returncode=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run([\"hdfs\", \"dfs\", \"-rm\", \"-r\", f'{HADOOP_PATH}/Output'])\n",
    "\n",
    "subprocess.run(\n",
    "    [\n",
    "        \"hadoop\",\n",
    "        \"jar\", \n",
    "        STREAMING_JAR,\n",
    "        \"-file\",\n",
    "        MAPPER_PATH,\n",
    "        \"-file\",\n",
    "        REDUCER_PATH,\n",
    "        \"-input\",\n",
    "        f'{HADOOP_PATH}/Input',\n",
    "        \"-output\",\n",
    "        f'{HADOOP_PATH}/Output',\n",
    "        \"-mapper\",\n",
    "        f'{MAPPER_PATH} {epochs} {alpha}',\n",
    "        \"-reducer\",\n",
    "        f'{REDUCER_PATH}'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dda6ff5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-20T19:31:52.206175Z",
     "start_time": "2022-05-20T19:31:50.657554Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-20 21:31:51,294 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,-0.7144573037575762\t\n",
      "1,0.12912702550131577\t\n",
      "10,0.09820548608328562\t\n",
      "11,-0.001327100918906068\t\n",
      "12,0.10297683497559008\t\n",
      "13,0.847159993965653\t\n",
      "14,0.23111291501349718\t\n",
      "15,0.23526637275705548\t\n",
      "16,-0.12299507050024866\t\n",
      "17,1.6531728440025901\t\n",
      "18,-0.5573639063375297\t\n",
      "19,-0.4555771010476153\t\n",
      "2,0.44043283048774834\t\n",
      "20,0.5741756860539273\t\n",
      "21,-0.21538499434841513\t\n",
      "22,1.2511612970072081\t\n",
      "23,0.055799086493396086\t\n",
      "24,-0.05537501781638641\t\n",
      "25,-0.061042177697221284\t\n",
      "26,0.564246015037948\t\n",
      "27,0.27804123052794083\t\n",
      "28,-1.5984819071400043\t\n",
      "29,-0.4693249829775594\t\n",
      "3,0.24674655627851183\t\n",
      "4,-0.04545293006039591\t\n",
      "5,0.06538121725783279\t\n",
      "6,-0.004772131446007549\t\n",
      "7,0.037373684074283965\t\n",
      "8,0.06946020189358049\t\n",
      "9,0.12708481855004816\t\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['hdfs', 'dfs', '-cat', '/LogReg/Output/*'], returncode=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run([\"hdfs\", \"dfs\", \"-cat\", f'{HADOOP_PATH}/Output/*'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caa5ca6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-20T19:31:54.183978Z",
     "start_time": "2022-05-20T19:31:52.439392Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-20 21:31:53,181 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part-00000\n",
      "_SUCCESS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['ls', 'Output'], returncode=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run([\"rm\", \"-r\", f'{os.getcwd()}/Output'])\n",
    "subprocess.run([\"hdfs\", \"dfs\", \"-get\", f'{HADOOP_PATH}/Output/', os.getcwd()])\n",
    "\n",
    "subprocess.run([\"ls\", 'Output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d46a8f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-20T19:31:54.385131Z",
     "start_time": "2022-05-20T19:31:54.367199Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>w</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.714457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.129127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.440433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.246747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.045453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index         w\n",
       "0      0 -0.714457\n",
       "1      1  0.129127\n",
       "2      2  0.440433\n",
       "3      3  0.246747\n",
       "4      4 -0.045453"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = pd.read_csv('Output/part-00000', header=None, names=[\"index\", \"w\"])\n",
    "out = out.sort_values('index').reset_index(drop=True)\n",
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94566257",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-20T19:31:54.696959Z",
     "start_time": "2022-05-20T19:31:54.688930Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 1)\n"
     ]
    }
   ],
   "source": [
    "w = out['w'].to_numpy().reshape(-1, 1)\n",
    "print(w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a10aef39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-20T19:31:55.434867Z",
     "start_time": "2022-05-20T19:31:55.115077Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34842, 29)\n",
      "(34842, 1)\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv('../test.csv', header=None)\n",
    "X_test = test_data.iloc[: , :-1].to_numpy()\n",
    "y_test = test_data.iloc[: , -1].to_numpy().reshape(-1,1)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f975114d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-20T19:31:56.296218Z",
     "start_time": "2022-05-20T19:31:56.288709Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34842, 30)\n"
     ]
    }
   ],
   "source": [
    "X_test_aug = np.pad(X_test, [(0,0), (1,0)], mode='constant', constant_values=1)\n",
    "print(X_test_aug.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2e29a2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-20T19:31:57.283860Z",
     "start_time": "2022-05-20T19:31:57.130195Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Logistic Regression is : 0.7928936341197406\n",
      "Confusion Matrix : \n",
      "[[21088   889]\n",
      " [ 6327  6538]]\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.96      0.85     21977\n",
      "           1       0.88      0.51      0.64     12865\n",
      "\n",
      "    accuracy                           0.79     34842\n",
      "   macro avg       0.82      0.73      0.75     34842\n",
      "weighted avg       0.81      0.79      0.78     34842\n",
      "\n"
     ]
    }
   ],
   "source": [
    "probs = X_test_aug @ w\n",
    "predictions = np.where(probs > 0.5, 1, 0)\n",
    "acc_lr = accuracy_score(y_test, predictions)\n",
    "conf = confusion_matrix(y_test, predictions)\n",
    "clf_report = classification_report(y_test, predictions)\n",
    "\n",
    "print(f\"Accuracy Score of Logistic Regression is : {acc_lr}\")\n",
    "print(f\"Confusion Matrix : \\n{conf}\")\n",
    "print(f\"Classification Report : \\n{clf_report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961452de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
