{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a6b66d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T12:15:05.255742Z",
     "start_time": "2022-05-06T12:15:04.542774Z"
    }
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61e540b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T12:15:05.262106Z",
     "start_time": "2022-05-06T12:15:05.257900Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "alpha = 0.001\n",
    "HADOOP_PATH = '/LogReg'\n",
    "INPUT_PATH = '/home/islamahmed1092/Desktop/hotel-booking-demand-analysis/train.csv'\n",
    "MAPPER_PATH = '/home/islamahmed1092/Desktop/hotel-booking-demand-analysis/LogReg/mapper.py'\n",
    "REDUCER_PATH = '/home/islamahmed1092/Desktop/hotel-booking-demand-analysis/LogReg/reducer.py'\n",
    "STREAMING_JAR = '/usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.3.0.jar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9af8f0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T12:15:05.947115Z",
     "start_time": "2022-05-06T12:15:05.266812Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81298, 29)\n",
      "(81298, 1)\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('../train.csv', header=None)\n",
    "X_train = train_data.iloc[: , :-1].to_numpy()\n",
    "y_train = train_data.iloc[: , -1].to_numpy().reshape(-1,1)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b38e0aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T12:15:05.952427Z",
     "start_time": "2022-05-06T12:15:05.948633Z"
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "def cost(y, yhat):\n",
    "    cost = -(y*np.log(yhat) + (1-y)*log(1-yhat))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45e5cece",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T12:15:05.965061Z",
     "start_time": "2022-05-06T12:15:05.954179Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81298, 30)\n"
     ]
    }
   ],
   "source": [
    "X_train_aug = np.pad(X_train, [(0,0), (1,0)], mode='constant', constant_values=1)\n",
    "print(X_train_aug.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bc21617",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T12:15:05.970140Z",
     "start_time": "2022-05-06T12:15:05.966837Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 1)\n"
     ]
    }
   ],
   "source": [
    "w = np.zeros((X_train_aug.shape[1], 1))\n",
    "print(w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d5c5e95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T12:15:05.980580Z",
     "start_time": "2022-05-06T12:15:05.972147Z"
    }
   },
   "outputs": [],
   "source": [
    "# for epoch in range(epochs):\n",
    "#     for i in range(X_train.shape[0]):\n",
    "#         x = np.insert(X_train[i], 0, 1).reshape(-1,1)\n",
    "#         y = y_train[i]\n",
    "        \n",
    "#         yhat = sigmoid(w.T @ x).squeeze()\n",
    "#         grad = (yhat - y) * x\n",
    "#         w = w - alpha * grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c27c517",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T12:15:05.987786Z",
     "start_time": "2022-05-06T12:15:05.982675Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09314274",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T12:15:06.020685Z",
     "start_time": "2022-05-06T12:15:05.992030Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81298, 1)\n"
     ]
    }
   ],
   "source": [
    "probs = X_train_aug @ w\n",
    "predictions = np.where(probs > 0.5, 1, 0)\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d923d3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T12:15:06.237523Z",
     "start_time": "2022-05-06T12:15:06.022552Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Logistic Regression is : 0.6316883564171321\n",
      "Confusion Matrix : \n",
      "[[51355     0]\n",
      " [29943     0]]\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      1.00      0.77     51355\n",
      "           1       0.00      0.00      0.00     29943\n",
      "\n",
      "    accuracy                           0.63     81298\n",
      "   macro avg       0.32      0.50      0.39     81298\n",
      "weighted avg       0.40      0.63      0.49     81298\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/islamahmed1092/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/islamahmed1092/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/islamahmed1092/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "acc_lr = accuracy_score(y_train, predictions)\n",
    "conf = confusion_matrix(y_train, predictions)\n",
    "clf_report = classification_report(y_train, predictions)\n",
    "\n",
    "print(f\"Accuracy Score of Logistic Regression is : {acc_lr}\")\n",
    "print(f\"Confusion Matrix : \\n{conf}\")\n",
    "print(f\"Classification Report : \\n{clf_report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a10aef39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T12:15:06.527874Z",
     "start_time": "2022-05-06T12:15:06.239160Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34842, 29)\n",
      "(34842, 1)\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv('../test.csv', header=None)\n",
    "X_test = test_data.iloc[: , :-1].to_numpy()\n",
    "y_test = test_data.iloc[: , -1].to_numpy().reshape(-1,1)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f975114d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T12:15:06.539136Z",
     "start_time": "2022-05-06T12:15:06.529678Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34842, 30)\n",
      "(34842, 1)\n"
     ]
    }
   ],
   "source": [
    "X_test_aug = np.pad(X_test, [(0,0), (1,0)], mode='constant', constant_values=1)\n",
    "print(X_test_aug.shape)\n",
    "probs = X_test_aug @ w\n",
    "predictions = np.where(probs > 0.5, 1, 0)\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c44c7469",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T12:15:06.627887Z",
     "start_time": "2022-05-06T12:15:06.540750Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Logistic Regression is : 0.6356695941679582\n",
      "Confusion Matrix : \n",
      "[[22148     0]\n",
      " [12694     0]]\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      1.00      0.78     22148\n",
      "           1       0.00      0.00      0.00     12694\n",
      "\n",
      "    accuracy                           0.64     34842\n",
      "   macro avg       0.32      0.50      0.39     34842\n",
      "weighted avg       0.40      0.64      0.49     34842\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/islamahmed1092/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/islamahmed1092/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/islamahmed1092/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "acc_lr = accuracy_score(y_test, predictions)\n",
    "conf = confusion_matrix(y_test, predictions)\n",
    "clf_report = classification_report(y_test, predictions)\n",
    "\n",
    "print(f\"Accuracy Score of Logistic Regression is : {acc_lr}\")\n",
    "print(f\"Confusion Matrix : \\n{conf}\")\n",
    "print(f\"Classification Report : \\n{clf_report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cd31860",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T12:15:13.678538Z",
     "start_time": "2022-05-06T12:15:06.629487Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 14:15:07,331 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted /LogReg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 14:15:08,846 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2022-05-06 14:15:10,729 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2022-05-06 14:15:12,468 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['hdfs', 'dfs', '-put', '/home/islamahmed1092/Desktop/hotel-booking-demand-analysis/train.csv', '/LogReg/Input'], returncode=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run([\"hdfs\", \"dfs\", \"-rm\", \"-r\", HADOOP_PATH])\n",
    "subprocess.run([\"hdfs\", \"dfs\", \"-mkdir\", HADOOP_PATH])\n",
    "subprocess.run([\"hdfs\", \"dfs\", \"-mkdir\", f'{HADOOP_PATH}/Input'])\n",
    "subprocess.run([\"hdfs\", \"dfs\", \"-put\", INPUT_PATH, f'{HADOOP_PATH}/Input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fa5a3f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T12:16:21.843813Z",
     "start_time": "2022-05-06T12:15:13.685031Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 14:15:14,475 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "rm: `/LogReg/Output': No such file or directory\n",
      "2022-05-06 14:15:16,098 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.\n",
      "2022-05-06 14:15:16,242 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "packageJobJar: [/home/islamahmed1092/Desktop/hotel-booking-demand-analysis/LogReg/mapper.py, /home/islamahmed1092/Desktop/hotel-booking-demand-analysis/LogReg/reducer.py, /tmp/hadoop-unjar1246238965075856085/] [] /tmp/streamjob10328717910516916972.jar tmpDir=null\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 14:15:17,001 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2022-05-06 14:15:17,176 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2022-05-06 14:15:17,407 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/islamahmed1092/.staging/job_1651835008910_0012\n",
      "2022-05-06 14:15:17,699 INFO mapred.FileInputFormat: Total input files to process : 1\n",
      "2022-05-06 14:15:17,734 INFO mapreduce.JobSubmitter: number of splits:2\n",
      "2022-05-06 14:15:17,952 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1651835008910_0012\n",
      "2022-05-06 14:15:17,952 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
      "2022-05-06 14:15:18,120 INFO conf.Configuration: resource-types.xml not found\n",
      "2022-05-06 14:15:18,120 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.\n",
      "2022-05-06 14:15:18,169 INFO impl.YarnClientImpl: Submitted application application_1651835008910_0012\n",
      "2022-05-06 14:15:18,219 INFO mapreduce.Job: The url to track the job: http://islamahmed1092:8088/proxy/application_1651835008910_0012/\n",
      "2022-05-06 14:15:18,220 INFO mapreduce.Job: Running job: job_1651835008910_0012\n",
      "2022-05-06 14:15:24,326 INFO mapreduce.Job: Job job_1651835008910_0012 running in uber mode : false\n",
      "2022-05-06 14:15:24,328 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "2022-05-06 14:15:40,444 INFO mapreduce.Job:  map 67% reduce 0%\n",
      "2022-05-06 14:16:16,604 INFO mapreduce.Job:  map 83% reduce 0%\n",
      "2022-05-06 14:16:19,618 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "2022-05-06 14:16:21,631 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "2022-05-06 14:16:21,651 INFO mapreduce.Job: Job job_1651835008910_0012 completed successfully\n",
      "2022-05-06 14:16:21,780 INFO mapreduce.Job: Counters: 54\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=1484\n",
      "\t\tFILE: Number of bytes written=807510\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=47466401\n",
      "\t\tHDFS: Number of bytes written=713\n",
      "\t\tHDFS: Number of read operations=11\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tData-local map tasks=2\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=103887\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=2771\n",
      "\t\tTotal time spent by all map tasks (ms)=103887\n",
      "\t\tTotal time spent by all reduce tasks (ms)=2771\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=103887\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=2771\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=106380288\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=2837504\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=81298\n",
      "\t\tMap output records=60\n",
      "\t\tMap output bytes=1358\n",
      "\t\tMap output materialized bytes=1490\n",
      "\t\tInput split bytes=192\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=30\n",
      "\t\tReduce shuffle bytes=1490\n",
      "\t\tReduce input records=60\n",
      "\t\tReduce output records=30\n",
      "\t\tSpilled Records=120\n",
      "\t\tShuffled Maps =2\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tGC time elapsed (ms)=71\n",
      "\t\tCPU time spent (ms)=26830\n",
      "\t\tPhysical memory (bytes) snapshot=751525888\n",
      "\t\tVirtual memory (bytes) snapshot=8241463296\n",
      "\t\tTotal committed heap usage (bytes)=608174080\n",
      "\t\tPeak Map Physical memory (bytes)=331014144\n",
      "\t\tPeak Map Virtual memory (bytes)=3025940480\n",
      "\t\tPeak Reduce Physical memory (bytes)=195768320\n",
      "\t\tPeak Reduce Virtual memory (bytes)=2752294912\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=47466209\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=713\n",
      "2022-05-06 14:16:21,780 INFO streaming.StreamJob: Output directory: /LogReg/Output\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['hadoop', 'jar', '/usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.3.0.jar', '-file', '/home/islamahmed1092/Desktop/hotel-booking-demand-analysis/LogReg/mapper.py', '-file', '/home/islamahmed1092/Desktop/hotel-booking-demand-analysis/LogReg/reducer.py', '-input', '/LogReg/Input', '-output', '/LogReg/Output', '-mapper', '/home/islamahmed1092/Desktop/hotel-booking-demand-analysis/LogReg/mapper.py 100 0.001', '-reducer', '/home/islamahmed1092/Desktop/hotel-booking-demand-analysis/LogReg/reducer.py'], returncode=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run([\"hdfs\", \"dfs\", \"-rm\", \"-r\", f'{HADOOP_PATH}/Output'])\n",
    "\n",
    "subprocess.run(\n",
    "    [\n",
    "        \"hadoop\",\n",
    "        \"jar\", \n",
    "        STREAMING_JAR,\n",
    "        \"-file\",\n",
    "        MAPPER_PATH,\n",
    "        \"-file\",\n",
    "        REDUCER_PATH,\n",
    "        \"-input\",\n",
    "        f'{HADOOP_PATH}/Input',\n",
    "        \"-output\",\n",
    "        f'{HADOOP_PATH}/Output',\n",
    "        \"-mapper\",\n",
    "        f'{MAPPER_PATH} {epochs} {alpha}',\n",
    "        \"-reducer\",\n",
    "        f'{REDUCER_PATH}'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4dda6ff5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T12:16:23.709981Z",
     "start_time": "2022-05-06T12:16:21.845919Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 14:16:22,685 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,-0.8557708890746714\t\n",
      "1,0.11405748300885006\t\n",
      "10,0.08499580081193367\t\n",
      "11,-0.020261606335308883\t\n",
      "12,0.0719543857423875\t\n",
      "13,0.8469970501724289\t\n",
      "14,0.2068545386329434\t\n",
      "15,0.25604381401082066\t\n",
      "16,-0.15494059840982521\t\n",
      "17,1.716941060743846\t\n",
      "18,-0.5669673909747577\t\n",
      "19,-0.44082069000083945\t\n",
      "2,0.43450457411676224\t\n",
      "20,0.5593389953258794\t\n",
      "21,-0.23562597659409845\t\n",
      "22,1.2635465367535526\t\n",
      "23,0.04426282687869723\t\n",
      "24,-0.044320986374034484\t\n",
      "25,-0.05264507989466281\t\n",
      "26,0.5466642916487978\t\n",
      "27,0.2905671091087319\t\n",
      "28,-2.2581125375201974\t\n",
      "29,-0.46154895231036513\t\n",
      "3,0.2786628317278258\t\n",
      "4,-0.041708555645396564\t\n",
      "5,0.10142220893861836\t\n",
      "6,-0.001543850324260576\t\n",
      "7,0.039663311435341464\t\n",
      "8,0.08301442215261196\t\n",
      "9,0.2740200225882914\t\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['hdfs', 'dfs', '-cat', '/LogReg/Output/*'], returncode=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run([\"hdfs\", \"dfs\", \"-cat\", f'{HADOOP_PATH}/Output/*'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "caa5ca6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T12:16:25.583606Z",
     "start_time": "2022-05-06T12:16:23.714376Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 14:16:24,609 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part-00000\n",
      "_SUCCESS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['ls', 'Output'], returncode=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run([\"rm\", \"-r\", f'{os.getcwd()}/Output'])\n",
    "subprocess.run([\"hdfs\", \"dfs\", \"-get\", f'{HADOOP_PATH}/Output/', os.getcwd()])\n",
    "\n",
    "subprocess.run([\"ls\", 'Output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d46a8f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T12:16:25.608950Z",
     "start_time": "2022-05-06T12:16:25.585952Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>w</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.855771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.114057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.434505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.278663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.041709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index         w\n",
       "0      0 -0.855771\n",
       "1      1  0.114057\n",
       "2      2  0.434505\n",
       "3      3  0.278663\n",
       "4      4 -0.041709"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = pd.read_csv('Output/part-00000', header=None, names=[\"index\", \"w\"])\n",
    "out = out.sort_values('index').reset_index(drop=True)\n",
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94566257",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T12:16:25.618822Z",
     "start_time": "2022-05-06T12:16:25.613680Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 1)\n"
     ]
    }
   ],
   "source": [
    "w = out['w'].to_numpy().reshape(-1, 1)\n",
    "print(w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2e29a2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T12:16:25.756602Z",
     "start_time": "2022-05-06T12:16:25.621859Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Logistic Regression is : 0.7943860857585673\n",
      "Confusion Matrix : \n",
      "[[21197   951]\n",
      " [ 6213  6481]]\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.96      0.86     22148\n",
      "           1       0.87      0.51      0.64     12694\n",
      "\n",
      "    accuracy                           0.79     34842\n",
      "   macro avg       0.82      0.73      0.75     34842\n",
      "weighted avg       0.81      0.79      0.78     34842\n",
      "\n"
     ]
    }
   ],
   "source": [
    "probs = X_test_aug @ w\n",
    "predictions = np.where(probs > 0.5, 1, 0)\n",
    "acc_lr = accuracy_score(y_test, predictions)\n",
    "conf = confusion_matrix(y_test, predictions)\n",
    "clf_report = classification_report(y_test, predictions)\n",
    "\n",
    "print(f\"Accuracy Score of Logistic Regression is : {acc_lr}\")\n",
    "print(f\"Confusion Matrix : \\n{conf}\")\n",
    "print(f\"Classification Report : \\n{clf_report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961452de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
