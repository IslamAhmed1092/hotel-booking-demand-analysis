{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a6b66d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T14:15:01.111029Z",
     "start_time": "2022-05-06T14:15:00.695673Z"
    }
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61e540b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T14:15:01.114893Z",
     "start_time": "2022-05-06T14:15:01.112289Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 300\n",
    "alpha = 0.1\n",
    "HADOOP_PATH = '/LogReg'\n",
    "INPUT_PATH = '/home/islamahmed1092/Desktop/hotel-booking-demand-analysis/train.csv'\n",
    "MAPPER_PATH = '/home/islamahmed1092/Desktop/hotel-booking-demand-analysis/LogReg/mapper.py'\n",
    "REDUCER_PATH = '/home/islamahmed1092/Desktop/hotel-booking-demand-analysis/LogReg/reducer.py'\n",
    "STREAMING_JAR = '/usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.3.0.jar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9af8f0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T14:15:01.566596Z",
     "start_time": "2022-05-06T14:15:01.116077Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81298, 32)\n",
      "(81298, 1)\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('../train.csv', header=None)\n",
    "X_train = train_data.iloc[: , :-1].to_numpy()\n",
    "y_train = train_data.iloc[: , -1].to_numpy().reshape(-1,1)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b38e0aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T14:15:01.570838Z",
     "start_time": "2022-05-06T14:15:01.568063Z"
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "def cost(y, yhat):\n",
    "    cost = -(y*np.log(yhat) + (1-y)*log(1-yhat))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45e5cece",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T14:15:01.582900Z",
     "start_time": "2022-05-06T14:15:01.571949Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81298, 33)\n"
     ]
    }
   ],
   "source": [
    "X_train_aug = np.pad(X_train, [(0,0), (1,0)], mode='constant', constant_values=1)\n",
    "print(X_train_aug.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bc21617",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T14:15:01.587449Z",
     "start_time": "2022-05-06T14:15:01.584302Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33, 1)\n"
     ]
    }
   ],
   "source": [
    "w = np.zeros((X_train_aug.shape[1], 1))\n",
    "print(w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d5c5e95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T14:15:01.591577Z",
     "start_time": "2022-05-06T14:15:01.589140Z"
    }
   },
   "outputs": [],
   "source": [
    "# for epoch in range(epochs):\n",
    "#     for i in range(X_train.shape[0]):\n",
    "#         x = np.insert(X_train[i], 0, 1).reshape(-1,1)\n",
    "#         y = y_train[i]\n",
    "        \n",
    "#         yhat = sigmoid(w.T @ x).squeeze()\n",
    "#         grad = (yhat - y) * x\n",
    "#         w = w - alpha * grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c27c517",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T14:15:01.597888Z",
     "start_time": "2022-05-06T14:15:01.593925Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09314274",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T14:15:01.627036Z",
     "start_time": "2022-05-06T14:15:01.599337Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81298, 1)\n"
     ]
    }
   ],
   "source": [
    "probs = X_train_aug @ w\n",
    "predictions = np.where(probs > 0.5, 1, 0)\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d923d3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T14:15:01.766110Z",
     "start_time": "2022-05-06T14:15:01.629105Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Logistic Regression is : 0.6335826219587197\n",
      "Confusion Matrix : \n",
      "[[51509     0]\n",
      " [29789     0]]\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      1.00      0.78     51509\n",
      "           1       0.00      0.00      0.00     29789\n",
      "\n",
      "    accuracy                           0.63     81298\n",
      "   macro avg       0.32      0.50      0.39     81298\n",
      "weighted avg       0.40      0.63      0.49     81298\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/islamahmed1092/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/islamahmed1092/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/islamahmed1092/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "acc_lr = accuracy_score(y_train, predictions)\n",
    "conf = confusion_matrix(y_train, predictions)\n",
    "clf_report = classification_report(y_train, predictions)\n",
    "\n",
    "print(f\"Accuracy Score of Logistic Regression is : {acc_lr}\")\n",
    "print(f\"Confusion Matrix : \\n{conf}\")\n",
    "print(f\"Classification Report : \\n{clf_report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a10aef39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T14:15:01.957096Z",
     "start_time": "2022-05-06T14:15:01.767158Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34842, 32)\n",
      "(34842, 1)\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv('../test.csv', header=None)\n",
    "X_test = test_data.iloc[: , :-1].to_numpy()\n",
    "y_test = test_data.iloc[: , -1].to_numpy().reshape(-1,1)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f975114d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T14:15:01.965912Z",
     "start_time": "2022-05-06T14:15:01.958324Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34842, 33)\n",
      "(34842, 1)\n"
     ]
    }
   ],
   "source": [
    "X_test_aug = np.pad(X_test, [(0,0), (1,0)], mode='constant', constant_values=1)\n",
    "print(X_test_aug.shape)\n",
    "probs = X_test_aug @ w\n",
    "predictions = np.where(probs > 0.5, 1, 0)\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c44c7469",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T14:15:02.024305Z",
     "start_time": "2022-05-06T14:15:01.966866Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Logistic Regression is : 0.6312496412375869\n",
      "Confusion Matrix : \n",
      "[[21994     0]\n",
      " [12848     0]]\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      1.00      0.77     21994\n",
      "           1       0.00      0.00      0.00     12848\n",
      "\n",
      "    accuracy                           0.63     34842\n",
      "   macro avg       0.32      0.50      0.39     34842\n",
      "weighted avg       0.40      0.63      0.49     34842\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/islamahmed1092/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/islamahmed1092/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/islamahmed1092/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "acc_lr = accuracy_score(y_test, predictions)\n",
    "conf = confusion_matrix(y_test, predictions)\n",
    "clf_report = classification_report(y_test, predictions)\n",
    "\n",
    "print(f\"Accuracy Score of Logistic Regression is : {acc_lr}\")\n",
    "print(f\"Confusion Matrix : \\n{conf}\")\n",
    "print(f\"Classification Report : \\n{clf_report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cd31860",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T14:15:06.674161Z",
     "start_time": "2022-05-06T14:15:02.025659Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 16:15:02,478 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted /LogReg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 16:15:03,512 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2022-05-06 16:15:04,571 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2022-05-06 16:15:05,749 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['hdfs', 'dfs', '-put', '/home/islamahmed1092/Desktop/hotel-booking-demand-analysis/train.csv', '/LogReg/Input'], returncode=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run([\"hdfs\", \"dfs\", \"-rm\", \"-r\", HADOOP_PATH])\n",
    "subprocess.run([\"hdfs\", \"dfs\", \"-mkdir\", HADOOP_PATH])\n",
    "subprocess.run([\"hdfs\", \"dfs\", \"-mkdir\", f'{HADOOP_PATH}/Input'])\n",
    "subprocess.run([\"hdfs\", \"dfs\", \"-put\", INPUT_PATH, f'{HADOOP_PATH}/Input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fa5a3f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T14:17:01.925393Z",
     "start_time": "2022-05-06T14:15:06.675671Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 16:15:07,175 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "rm: `/LogReg/Output': No such file or directory\n",
      "2022-05-06 16:15:08,129 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.\n",
      "2022-05-06 16:15:08,207 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "packageJobJar: [/home/islamahmed1092/Desktop/hotel-booking-demand-analysis/LogReg/mapper.py, /home/islamahmed1092/Desktop/hotel-booking-demand-analysis/LogReg/reducer.py, /tmp/hadoop-unjar4333037623252808435/] [] /tmp/streamjob63553551471458439.jar tmpDir=null\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 16:15:08,675 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2022-05-06 16:15:08,774 INFO client.DefaultNoHARMFailoverProxyProvider: Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2022-05-06 16:15:08,904 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/hadoop-yarn/staging/islamahmed1092/.staging/job_1651835008910_0025\n",
      "2022-05-06 16:15:09,078 INFO mapred.FileInputFormat: Total input files to process : 1\n",
      "2022-05-06 16:15:09,107 INFO mapreduce.JobSubmitter: number of splits:2\n",
      "2022-05-06 16:15:09,230 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1651835008910_0025\n",
      "2022-05-06 16:15:09,230 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
      "2022-05-06 16:15:09,366 INFO conf.Configuration: resource-types.xml not found\n",
      "2022-05-06 16:15:09,366 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.\n",
      "2022-05-06 16:15:09,408 INFO impl.YarnClientImpl: Submitted application application_1651835008910_0025\n",
      "2022-05-06 16:15:09,427 INFO mapreduce.Job: The url to track the job: http://islamahmed1092:8088/proxy/application_1651835008910_0025/\n",
      "2022-05-06 16:15:09,428 INFO mapreduce.Job: Running job: job_1651835008910_0025\n",
      "2022-05-06 16:15:14,492 INFO mapreduce.Job: Job job_1651835008910_0025 running in uber mode : false\n",
      "2022-05-06 16:15:14,494 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "2022-05-06 16:15:30,560 INFO mapreduce.Job:  map 67% reduce 0%\n",
      "2022-05-06 16:16:56,799 INFO mapreduce.Job:  map 83% reduce 0%\n",
      "2022-05-06 16:16:59,810 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "2022-05-06 16:17:00,815 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "2022-05-06 16:17:01,829 INFO mapreduce.Job: Job job_1651835008910_0025 completed successfully\n",
      "2022-05-06 16:17:01,899 INFO mapreduce.Job: Counters: 54\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=1613\n",
      "\t\tFILE: Number of bytes written=807753\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=51908776\n",
      "\t\tHDFS: Number of bytes written=774\n",
      "\t\tHDFS: Number of read operations=11\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\t\tHDFS: Number of bytes read erasure-coded=0\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=2\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tData-local map tasks=2\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=204753\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=1753\n",
      "\t\tTotal time spent by all map tasks (ms)=204753\n",
      "\t\tTotal time spent by all reduce tasks (ms)=1753\n",
      "\t\tTotal vcore-milliseconds taken by all map tasks=204753\n",
      "\t\tTotal vcore-milliseconds taken by all reduce tasks=1753\n",
      "\t\tTotal megabyte-milliseconds taken by all map tasks=209667072\n",
      "\t\tTotal megabyte-milliseconds taken by all reduce tasks=1795072\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=81298\n",
      "\t\tMap output records=66\n",
      "\t\tMap output bytes=1475\n",
      "\t\tMap output materialized bytes=1619\n",
      "\t\tInput split bytes=192\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=33\n",
      "\t\tReduce shuffle bytes=1619\n",
      "\t\tReduce input records=66\n",
      "\t\tReduce output records=33\n",
      "\t\tSpilled Records=132\n",
      "\t\tShuffled Maps =2\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tGC time elapsed (ms)=57\n",
      "\t\tCPU time spent (ms)=26320\n",
      "\t\tPhysical memory (bytes) snapshot=756891648\n",
      "\t\tVirtual memory (bytes) snapshot=8247885824\n",
      "\t\tTotal committed heap usage (bytes)=608174080\n",
      "\t\tPeak Map Physical memory (bytes)=348336128\n",
      "\t\tPeak Map Virtual memory (bytes)=3037683712\n",
      "\t\tPeak Reduce Physical memory (bytes)=185831424\n",
      "\t\tPeak Reduce Virtual memory (bytes)=2751361024\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=51908584\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=774\n",
      "2022-05-06 16:17:01,899 INFO streaming.StreamJob: Output directory: /LogReg/Output\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['hadoop', 'jar', '/usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.3.0.jar', '-file', '/home/islamahmed1092/Desktop/hotel-booking-demand-analysis/LogReg/mapper.py', '-file', '/home/islamahmed1092/Desktop/hotel-booking-demand-analysis/LogReg/reducer.py', '-input', '/LogReg/Input', '-output', '/LogReg/Output', '-mapper', '/home/islamahmed1092/Desktop/hotel-booking-demand-analysis/LogReg/mapper.py 300 0.1', '-reducer', '/home/islamahmed1092/Desktop/hotel-booking-demand-analysis/LogReg/reducer.py'], returncode=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run([\"hdfs\", \"dfs\", \"-rm\", \"-r\", f'{HADOOP_PATH}/Output'])\n",
    "\n",
    "subprocess.run(\n",
    "    [\n",
    "        \"hadoop\",\n",
    "        \"jar\", \n",
    "        STREAMING_JAR,\n",
    "        \"-file\",\n",
    "        MAPPER_PATH,\n",
    "        \"-file\",\n",
    "        REDUCER_PATH,\n",
    "        \"-input\",\n",
    "        f'{HADOOP_PATH}/Input',\n",
    "        \"-output\",\n",
    "        f'{HADOOP_PATH}/Output',\n",
    "        \"-mapper\",\n",
    "        f'{MAPPER_PATH} {epochs} {alpha}',\n",
    "        \"-reducer\",\n",
    "        f'{REDUCER_PATH}'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4dda6ff5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T14:17:03.073261Z",
     "start_time": "2022-05-06T14:17:01.926750Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 16:17:02,411 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0,15.037025481178684\t\n",
      "1,0.1202704005243329\t\n",
      "10,0.08187539578836955\t\n",
      "11,-0.5134501636996455\t\n",
      "12,0.18984711662878367\t\n",
      "13,1.1455254246772375\t\n",
      "14,0.2906992399269484\t\n",
      "15,-0.09932190380252724\t\n",
      "16,-0.20833487464954736\t\n",
      "17,0.43522320602086234\t\n",
      "18,-1.616987385892193\t\n",
      "19,-0.26184998498099654\t\n",
      "2,-0.0237854661799455\t\n",
      "20,0.3260857058482226\t\n",
      "21,-0.4766494083753955\t\n",
      "22,1.1881137579022263\t\n",
      "23,0.020485637387636972\t\n",
      "24,-0.1520372939923933\t\n",
      "25,-0.37259135303694146\t\n",
      "26,-0.03183521502208818\t\n",
      "27,0.1515385730898184\t\n",
      "28,-8.320479365039638\t\n",
      "29,-0.29097197459798485\t\n",
      "3,188.13557228174923\t\n",
      "30,-187.98086621654056\t\n",
      "31,-72.67207978109818\t\n",
      "32,-6.254174261692578\t\n",
      "4,0.455439187169039\t\n",
      "5,67.90975995224385\t\n",
      "6,0.15296573232349117\t\n",
      "7,-0.22142059726957508\t\n",
      "8,1.1164417959223538\t\n",
      "9,-0.23995230771507858\t\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['hdfs', 'dfs', '-cat', '/LogReg/Output/*'], returncode=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run([\"hdfs\", \"dfs\", \"-cat\", f'{HADOOP_PATH}/Output/*'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "caa5ca6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T14:17:04.542570Z",
     "start_time": "2022-05-06T14:17:03.074847Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 16:17:03,700 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part-00000\n",
      "_SUCCESS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['ls', 'Output'], returncode=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run([\"rm\", \"-r\", f'{os.getcwd()}/Output'])\n",
    "subprocess.run([\"hdfs\", \"dfs\", \"-get\", f'{HADOOP_PATH}/Output/', os.getcwd()])\n",
    "\n",
    "subprocess.run([\"ls\", 'Output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d46a8f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T14:17:04.564910Z",
     "start_time": "2022-05-06T14:17:04.543811Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>w</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>15.037025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.120270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.023785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>188.135572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.455439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index           w\n",
       "0      0   15.037025\n",
       "1      1    0.120270\n",
       "2      2   -0.023785\n",
       "3      3  188.135572\n",
       "4      4    0.455439"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = pd.read_csv('Output/part-00000', header=None, names=[\"index\", \"w\"])\n",
    "out = out.sort_values('index').reset_index(drop=True)\n",
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94566257",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T14:17:04.574613Z",
     "start_time": "2022-05-06T14:17:04.567111Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33, 1)\n"
     ]
    }
   ],
   "source": [
    "w = out['w'].to_numpy().reshape(-1, 1)\n",
    "print(w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2e29a2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-06T14:17:04.670117Z",
     "start_time": "2022-05-06T14:17:04.575762Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Logistic Regression is : 0.9675104758624649\n",
      "Confusion Matrix : \n",
      "[[21875   119]\n",
      " [ 1013 11835]]\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97     21994\n",
      "           1       0.99      0.92      0.95     12848\n",
      "\n",
      "    accuracy                           0.97     34842\n",
      "   macro avg       0.97      0.96      0.96     34842\n",
      "weighted avg       0.97      0.97      0.97     34842\n",
      "\n"
     ]
    }
   ],
   "source": [
    "probs = X_test_aug @ w\n",
    "predictions = np.where(probs > 0.5, 1, 0)\n",
    "acc_lr = accuracy_score(y_test, predictions)\n",
    "conf = confusion_matrix(y_test, predictions)\n",
    "clf_report = classification_report(y_test, predictions)\n",
    "\n",
    "print(f\"Accuracy Score of Logistic Regression is : {acc_lr}\")\n",
    "print(f\"Confusion Matrix : \\n{conf}\")\n",
    "print(f\"Classification Report : \\n{clf_report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961452de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
